# -*- coding: utf-8 -*-
"""final_rag_para_embed.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1aHjXMIZBk71xB219z_D8PZ7ZPCRMrs
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install sentence-transformers

from sentence_transformers import SentenceTransformer

# USING MODERN BERT

model = SentenceTransformer("nomic-ai/modernbert-embed-base")

def generate_embeddings(text):
    em = model.encode(text, reference_compile=False)
    return em

def eme(paras):
  final = []
  i = 0
  for p in paras:
    fake = generate_embeddings(p)
    final.append(fake)
    i = i+1
    print(i)
  return final

import joblib

import json

with open("/content/combined_paragraphs.json","r") as f:
  data=json.load(f)


#------------------------------------------------------------

x1=joblib.load("/content/embd_complete_paras_9000.pkl")

text_list = [entry["text"] for entry in data.values()]
text_list=text_list

x2=eme(text_list)

import joblib

joblib.dump(x2,"embd_complete_paras_9000.pkl")


# -----------------------------------------------------------
# %pip install pinecone

from pinecone import Pinecone

API_KEY = "please use your own api key"
if(API_KEY=="please use your own api key"):
    print("No valid API found")
    raise ValueError("Missing API key: Please use your own Pinecone Vector Database API key instead of the placeholder. Please check their docs for more.")

pc = Pinecone(api_key=API_KEY)

index_name = "quickstart" #PLEASE USE YOUR OWN INDEX NAME

index = pc.Index(index_name)



# -----------------------------------------------------------
# UPSERTING:


vectors = [
    {
        "id": str(i),
        "values": x1[i],
        "metadata": {"text": text_list[i]}
    }
    for i in range(len(x1))
]

for i in range(0, len(x1), 200):
  index.upsert(vectors = vectors[i:min(i+200, len(x1))])
  

# -----------------------------------------------------------

# CHECKING:

querry = "Wavelength of ZnO"
querry_e = generate_embeddings(querry)

results = index.query(
    vector=querry_e.tolist(),
    top_k=1000,
    include_metadata=True
)

count=0
for match in results.matches:
    print(count)
    print(f"ID: {match['id']}")
    print(f"Score: {match['score']}")
    print(f"Metadata: {match.get('metadata', 'No metadata')}")
    print("-----------")
    count=count+1

finals_ans=[]
for match in results.matches:
  finals_ans.append(match["metadata"]["text"])

count = 0
for lt in finals_ans:
    if "ZnO" in lt:
        count += 1
print(count)

